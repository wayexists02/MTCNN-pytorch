{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/list_landmarks_celeba.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "n = int(lines[0])\n",
    "labels = lines[1]\n",
    "label_splited = labels.split(\" \")[:10]\n",
    "label_splited.insert(0, \"image_id\")\n",
    "labels = \",\".join(map(lambda elem: elem.strip(), label_splited))\n",
    "\n",
    "with open(\"data/list_landmarks_celeba.csv\", \"w\") as f:\n",
    "    f.write(f\"{labels}\\n\")\n",
    "    for line in lines[2:]:\n",
    "        splited = []\n",
    "        for item in line.split(\" \"):\n",
    "            if len(item) > 0:\n",
    "                splited.append(item.strip())\n",
    "        \n",
    "        line = \",\".join(splited)\n",
    "        f.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/list_bbox_celeba.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "n = int(lines[0])\n",
    "labels = lines[1]\n",
    "label_splited = labels.split(\" \")[:10]\n",
    "labels = \",\".join(map(lambda elem: elem.strip(), label_splited))\n",
    "\n",
    "with open(\"data/list_bbox_celeba.csv\", \"w\") as f:\n",
    "    f.write(f\"{labels}\\n\")\n",
    "    for line in lines[2:]:\n",
    "        splited = []\n",
    "        for item in line.split(\" \"):\n",
    "            if len(item) > 0:\n",
    "                splited.append(item.strip())\n",
    "        \n",
    "        line = \",\".join(splited)\n",
    "        f.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/list_eval_partition.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "labels = \"image_id,partition\"\n",
    "\n",
    "with open(\"data/list_eval_partition.csv\", \"w\") as f:\n",
    "    f.write(f\"{labels}\\n\")\n",
    "    for line in lines:\n",
    "        splited = []\n",
    "        for item in line.split(\" \"):\n",
    "            if len(item) > 0:\n",
    "                splited.append(item.strip())\n",
    "        \n",
    "        line = \",\".join(splited)\n",
    "        f.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CELEBA Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT_FILE_PATH = \"data/list_eval_partition.csv\"\n",
    "LM_FILE_PATH = \"data/list_landmarks_celeba.csv\"\n",
    "BBOX_FILE_PATH = \"data/list_bbox_celeba.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  partition\n",
       "0  000001.jpg          0\n",
       "1  000002.jpg          0\n",
       "2  000003.jpg          0\n",
       "3  000004.jpg          0\n",
       "4  000005.jpg          0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_file = pd.read_csv(TRAIN_SPLIT_FILE_PATH)\n",
    "split_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     image_id  lefteye_x  lefteye_y  righteye_x  righteye_y  nose_x  nose_y  \\\n",
      "0  000001.jpg        165        184         244         176     196     249   \n",
      "1  000002.jpg        140        204         220         204     168     254   \n",
      "2  000003.jpg        244        104         264         105     263     121   \n",
      "3  000004.jpg        796        539         984         539     930     687   \n",
      "4  000005.jpg        273        169         328         161     298     172   \n",
      "\n",
      "   leftmouth_x  leftmouth_y  rightmouth_x  rightmouth_y  \n",
      "0          194          271           266           260  \n",
      "1          146          289           226           289  \n",
      "2          235          134           251           140  \n",
      "3          762          756           915           756  \n",
      "4          283          208           323           207  \n",
      "          image_id   x_1  y_1  width  height\n",
      "0       000001.jpg    95   71    226     313\n",
      "1       000002.jpg    72   94    221     306\n",
      "2       000003.jpg   216   59     91     126\n",
      "3       000004.jpg   622  257    564     781\n",
      "4       000005.jpg   236  109    120     166\n",
      "...            ...   ...  ...    ...     ...\n",
      "202594  202595.jpg  1381   91    221     306\n",
      "202595  202596.jpg   137  129    114     158\n",
      "202596  202597.jpg    53   76     91     126\n",
      "202597  202598.jpg   195   28     91     126\n",
      "202598  202599.jpg   101  101    179     248\n",
      "\n",
      "[202599 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lm_file = pd.read_csv(LM_FILE_PATH)\n",
    "print(lm_file.head())\n",
    "\n",
    "bbox_file = pd.read_csv(BBOX_FILE_PATH)\n",
    "print(bbox_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_split():\n",
    "    split_file = pd.read_csv(TRAIN_SPLIT_FILE_PATH)\n",
    "    \n",
    "    path = split_file[\"image_id\"]\n",
    "    partition = split_file[\"partition\"]\n",
    "    \n",
    "    train_paths = path[partition == 0]\n",
    "    valid_paths = path[partition == 1]\n",
    "    test_paths = path[partition == 2]\n",
    "    \n",
    "    return train_paths, valid_paths, test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    000001.jpg\n",
      "1    000002.jpg\n",
      "2    000003.jpg\n",
      "3    000004.jpg\n",
      "4    000005.jpg\n",
      "Name: image_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = train_eval_split()\n",
    "print(train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_celeba_data(dataset, cat):\n",
    "    \n",
    "    if not os.path.exists(\"data/celeba\") or not os.path.isdir(\"data/celeba\"):\n",
    "        os.mkdir(\"data/celeba\")\n",
    "        os.mkdir(\"data/celeba/train\")\n",
    "        os.mkdir(\"data/celeba/valid\")\n",
    "        os.mkdir(\"data/celeba/test\")\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for filename in dataset:\n",
    "        frompath = os.path.join(\"data\", \"img_celeba\", filename).replace(\"\\\\\", \"/\")\n",
    "        topath = os.path.join(\"data\", \"celeba\", cat, filename).replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        shutil.move(frompath, topath)\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    print(f\"Dataset counts: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset counts: 162770\n",
      "Dataset counts: 19867\n",
      "Dataset counts: 19962\n"
     ]
    }
   ],
   "source": [
    "copy_celeba_data(train, \"train\")\n",
    "copy_celeba_data(valid, \"valid\")\n",
    "copy_celeba_data(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_split(train, valid, test):\n",
    "    train_lm = lm_file[lm_file[\"image_id\"].isin(train)]\n",
    "    valid_lm = lm_file[lm_file[\"image_id\"].isin(valid)]\n",
    "    test_lm = lm_file[lm_file[\"image_id\"].isin(test)]\n",
    "    \n",
    "    train_bbox = bbox_file[bbox_file[\"image_id\"].isin(train)]\n",
    "    valid_bbox = bbox_file[bbox_file[\"image_id\"].isin(valid)]\n",
    "    test_bbox = bbox_file[bbox_file[\"image_id\"].isin(test)]\n",
    "    \n",
    "    train_lm.to_csv(\"data/celeba/train_lm.csv\")\n",
    "    valid_lm.to_csv(\"data/celeba/valid_lm.csv\")\n",
    "    test_lm.to_csv(\"data/celeba/test_lm.csv\")\n",
    "    \n",
    "    train_bbox.to_csv(\"data/celeba/train_bbox.csv\")\n",
    "    valid_bbox.to_csv(\"data/celeba/valid_bbox.csv\")\n",
    "    test_bbox.to_csv(\"data/celeba/test_bbox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_split(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIDER Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_wider():\n",
    "    os.mkdir(\"data/wider\")\n",
    "    \n",
    "    os.mkdir(\"data/wider/train\")\n",
    "    os.mkdir(\"data/wider/valid\")\n",
    "    os.mkdir(\"data/wider/test\")\n",
    "    \n",
    "    for orig_cat in [\"train\", \"val\"]:\n",
    "        wider_annot_path = f\"data/wider_face_split/wider_face_{orig_cat}_bbx_gt.txt\"\n",
    "        cat = orig_cat\n",
    "        if orig_cat == \"val\":\n",
    "            cat = \"valid\"\n",
    "        \n",
    "        flags = \"name\"\n",
    "        \n",
    "        filename = None\n",
    "        dataset = []\n",
    "        \n",
    "        with open(wider_annot_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                if flags == \"name\":\n",
    "                    filename = line.replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "                    flags = \"num\"\n",
    "                    \n",
    "                elif flags == \"num\":\n",
    "                    num = int(line)\n",
    "                    cnt = num\n",
    "                    bboxes = []\n",
    "                        \n",
    "                    flags = \"bbox\"\n",
    "                    \n",
    "                elif flags == \"bbox\":\n",
    "                    if cnt > 0:\n",
    "                        x, y, w, h = list(map(float, line.split(\" \")[:4]))\n",
    "                        bboxes.append((x, y, w, h))\n",
    "                        cnt -= 1\n",
    "                    \n",
    "                    if cnt == 0:\n",
    "                        from_path = f\"data/WIDER_{orig_cat}/images/\" + filename\n",
    "                        to_path = f\"data/wider/{cat}\"\n",
    "                        \n",
    "                        shutil.move(from_path, to_path)\n",
    "                        filename = filename.split(\"/\")[1]\n",
    "\n",
    "                        data_sample = [filename, bboxes]\n",
    "                        dataset.append(data_sample)\n",
    "\n",
    "                        flags = \"name\"\n",
    "            \n",
    "        print(f\"{cat}: {len(dataset)}\")\n",
    "            \n",
    "        with open(f\"data/wider/wider_{cat}.bin\", \"wb\") as f:\n",
    "            dump_str = pickle.dumps(dataset)\n",
    "            f.write(dump_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 12880\n",
      "valid: 3226\n"
     ]
    }
   ],
   "source": [
    "rearrange_wider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
